{
 "metadata": {
  "name": "bayesian_sample"
 }, 
 "nbformat": 2, 
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code", 
     "collapsed": true, 
     "input": [
      "import numpy as np", 
      "import pymc as pm", 
      "from scipy.stats import ks_2samp"
     ], 
     "language": "python", 
     "outputs": [], 
     "prompt_number": 1
    }, 
    {
     "cell_type": "code", 
     "collapsed": false, 
     "input": [
      "## generate test data", 
      "tau = pm.rdiscrete_uniform(0,300)", 
      "alpha = 1./20.", 
      "lambda_a,lambda_b = pm.rexponential(alpha,2)", 
      "count_data = np.r_[pm.rpoisson(lambda_a, tau), pm.rpoisson(lambda_b, 1000-tau)]", 
      "count_data = np.array(count_data)", 
      "print lambda_a,lambda_b"
     ], 
     "language": "python", 
     "outputs": [
      {
       "output_type": "stream", 
       "stream": "stdout", 
       "text": [
        "60.6144407572 25.7293207473"
       ]
      }
     ], 
     "prompt_number": 28
    }, 
    {
     "cell_type": "code", 
     "collapsed": false, 
     "input": [
      "## setup model parameters.. the priors ", 
      "n_count_data = len(count_data)", 
      "alpha = 1.0 / count_data.mean()  # Recall count_data is the", 
      "lambda_1 = pm.Exponential(\"lambda_1\", alpha)", 
      "lambda_2 = pm.Exponential(\"lambda_2\", alpha)", 
      "tau = pm.DiscreteUniform(\"tau\", lower=0, upper=n_count_data)"
     ], 
     "language": "python", 
     "outputs": [], 
     "prompt_number": 29
    }, 
    {
     "cell_type": "code", 
     "collapsed": true, 
     "input": [
      "## setup model ", 
      "@pm.deterministic", 
      "def lambda_(tau=tau, lambda_1=lambda_1, lambda_2=lambda_2):", 
      "    out = np.zeros(n_count_data)", 
      "    out[:tau] = lambda_1  # lambda before tau is lambda1", 
      "    out[tau:] = lambda_2  # lambda after (and including) tau is lambda2", 
      "    return out", 
      "", 
      "observation = pm.Poisson(\"obs\", lambda_, value=count_data, observed=True)", 
      "model = pm.Model([observation, lambda_1, lambda_2, tau],verbose=5)"
     ], 
     "language": "python", 
     "outputs": [], 
     "prompt_number": 30
    }, 
    {
     "cell_type": "code", 
     "collapsed": false, 
     "input": [
      "## run model in markov chain monte carlo", 
      "mcmc = pm.MCMC(model)", 
      "mcmc.sample(10000, 4000, thin=4)", 
      "print 'ending'", 
      "lambda_1_samples = mcmc.trace('lambda_1')[:]", 
      "lambda_2_samples = mcmc.trace('lambda_2')[:]", 
      "tau_samples = mcmc.trace('tau')[:]"
     ], 
     "language": "python", 
     "outputs": [
      {
       "output_type": "stream", 
       "stream": "stdout", 
       "text": [
        "", 
        " [---               9%                  ] 984 of 10000 complete in 0.5 sec"
       ]
      }, 
      {
       "output_type": "stream", 
       "stream": "stdout", 
       "text": [
        "", 
        " [--------         22%                  ] 2232 of 10000 complete in 1.0 sec"
       ]
      }, 
      {
       "output_type": "stream", 
       "stream": "stdout", 
       "text": [
        "", 
        " [-------------    34%                  ] 3442 of 10000 complete in 1.5 sec"
       ]
      }, 
      {
       "output_type": "stream", 
       "stream": "stdout", 
       "text": [
        "", 
        " [-----------------46%                  ] 4639 of 10000 complete in 2.0 sec"
       ]
      }, 
      {
       "output_type": "stream", 
       "stream": "stdout", 
       "text": [
        "", 
        " [-----------------58%--                ] 5830 of 10000 complete in 2.5 sec"
       ]
      }, 
      {
       "output_type": "stream", 
       "stream": "stdout", 
       "text": [
        "", 
        " [-----------------70%------            ] 7002 of 10000 complete in 3.0 sec"
       ]
      }, 
      {
       "output_type": "stream", 
       "stream": "stdout", 
       "text": [
        "", 
        " [-----------------81%-----------       ] 8158 of 10000 complete in 3.5 sec"
       ]
      }, 
      {
       "output_type": "stream", 
       "stream": "stdout", 
       "text": [
        "", 
        " [-----------------93%---------------   ] 9319 of 10000 complete in 4.0 sec"
       ]
      }, 
      {
       "output_type": "stream", 
       "stream": "stdout", 
       "text": [
        "", 
        " [-----------------100%-----------------] 10000 of 10000 complete in 4.3 sec"
       ]
      }, 
      {
       "output_type": "stream", 
       "stream": "stdout", 
       "text": [
        "ending"
       ]
      }
     ], 
     "prompt_number": 31
    }, 
    {
     "cell_type": "code", 
     "collapsed": false, 
     "input": [
      "print lambda_1_samples.mean(),lambda_2_samples.mean()"
     ], 
     "language": "python", 
     "outputs": [
      {
       "output_type": "stream", 
       "stream": "stdout", 
       "text": [
        "60.6993063146 25.612657363"
       ]
      }
     ], 
     "prompt_number": 32
    }, 
    {
     "cell_type": "code", 
     "collapsed": true, 
     "input": [], 
     "language": "python", 
     "outputs": []
    }
   ]
  }
 ]
}